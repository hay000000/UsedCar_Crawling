import requests
import pandas as pd
import time
import logging
from pathlib import Path

# 1. ê²½ë¡œ ì„¤ì •
BASE_DIR = Path(__file__).resolve().parent
RESULT_DIR = BASE_DIR / "result"
RESULT_DIR.mkdir(parents=True, exist_ok=True)

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
logger = logging.getLogger(__name__)

class HeyDealerGradeMapper:
    def __init__(self):
        self.api_base = "https://api.heydealer.com/v2/customers/web/market/car_meta"
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
            'Accept': 'application/json'
        })
        self.final_file_path = RESULT_DIR / "heydealeer_brand.csv"
        
        # ìœˆë„ìš° ê²½ë¡œ ë³€í™˜ (f-string ì™¸ë¶€ì—ì„œ ì²˜ë¦¬)
        linux_path_str = str(self.final_file_path)
        win_path_suffix = linux_path_str.replace('/', '\\')
        self.win_path = f"\\\\wsl.localhost\\Ubuntu-22.04{win_path_suffix}"

    def get_json(self, url):
        try:
            time.sleep(0.1) # ì°¨ë‹¨ ë°©ì§€ ë° ì†ë„ í™•ë³´
            resp = self.session.get(url, timeout=10)
            return resp.json() if resp.status_code == 200 else None
        except:
            return None

    def run(self):
        logger.info("ğŸš€ [ë¸Œëœë“œ > ëª¨ë¸ > ì†Œë¶„ë¥˜ > ë“±ê¸‰] ìˆ˜ì§‘ ì‹œì‘")
        
        brands = self.get_json(f"{self.api_base}/brands/")
        if not brands: return

        all_mapping = []
        for b in brands:
            b_name, b_hash = b.get('name'), b.get('hash_id')
            logger.info(f"â–¶ï¸ ë¸Œëœë“œ: {b_name}")

            models_data = self.get_json(f"{self.api_base}/brands/{b_hash}/")
            if not models_data: continue

            for m in models_data.get('model_groups', []):
                m_name, m_hash = m.get('name'), m.get('hash_id')
                
                sub_data = self.get_json(f"{self.api_base}/model_groups/{m_hash}/")
                if not sub_data or not sub_data.get('models'): continue

                for s in sub_data['models']:
                    s_name, s_hash = s.get('name'), s.get('hash_id')
                    s_period = s.get('period', '-')

                    # âœ¨ ë“±ê¸‰(grades) ì •ë³´ í˜¸ì¶œ
                    detail_data = self.get_json(f"{self.api_base}/models/{s_hash}/")
                    
                    # grades ì •ë³´ê°€ ì—†ìœ¼ë©´ ì†Œë¶„ë¥˜ ì •ë³´ë¥¼ ê¸°ë³¸ìœ¼ë¡œ ì…ë ¥
                    if not detail_data or 'grades' not in detail_data or not detail_data['grades']:
                        # all_mapping.append({
                        #     "ëŒ€ë¶„ë¥˜(ë¸Œëœë“œ)": b_name, "ì¤‘ë¶„ë¥˜(ëª¨ë¸)": m_name,
                        #     "ì†Œë¶„ë¥˜(ìƒì„¸)": s_name, "ì„¸ë¶€íŠ¸ë¦¼(ë“±ê¸‰)": "-",
                        #     "ìƒì‚°ì‹œê¸°": s_period, "ë§¤ë¬¼ìˆ˜": s.get('count', 0)
                        # })
                        all_mapping.append({
                            "brand_name": b_name,
                            "brand_id": b_hash,
                            "model_group_name": m_name,
                            "model_group_id": m_hash,
                            "model_name": s_name,
                            "model_id": s_hash,
                            "grade_name": "-",
                            "grade_id": "-",
                            "production_period": s_period,
                            "listing_count": s.get('count', 0)
                        })
                        continue

                    # grades(ë“±ê¸‰) ë‹¨ê³„ê¹Œì§€ë§Œ ìˆ˜ì§‘
                    for g in detail_data['grades']:
                        # all_mapping.append({
                        #     "ëŒ€ë¶„ë¥˜(ë¸Œëœë“œ)": b_name,
                        #     "ì¤‘ë¶„ë¥˜(ëª¨ë¸)": m_name,
                        #     "ì†Œë¶„ë¥˜(ìƒì„¸)": s_name,
                        #     "ì„¸ë¶€íŠ¸ë¦¼(ë“±ê¸‰)": g.get('name'), # ë“±ê¸‰ëª… (í”„ë¦¬ë¯¸ì—„ ë“±)
                        #     "ìƒì‚°ì‹œê¸°": s_period,
                        #     "ë§¤ë¬¼ìˆ˜": g.get('count', 0) # ë“±ê¸‰ë³„ ë§¤ë¬¼ ìˆ˜
                        # })
                        all_mapping.append({
                            "brand_name": b_name,
                            "brand_id": b_hash,
                            "model_group_name": m_name,
                            "model_group_id": m_hash,
                            "model_name": s_name,
                            "model_id": s_hash,
                            "grade_name": g.get('name'), # ë“±ê¸‰ëª… (ì˜ˆ: í”„ë¦¬ë¯¸ì—„)
                            "grade_id": g.get('hash_id'), # ë“±ê¸‰ ID
                            "production_period": s_period,
                            "listing_count": g.get('count', 0) # ë“±ê¸‰ë³„ ë§¤ë¬¼ ìˆ˜
                        })
            
            # ë¸Œëœë“œ ì™„ë£Œ ì‹œì ë§ˆë‹¤ íŒŒì¼ ì €ì¥
            self.save_to_csv(all_mapping)

        logger.info("\n" + "="*70)
        logger.info(f"âœ¨ ë¸Œëœë“œ ë¶„ë¥˜ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ! íŒŒì¼ ìœ„ì¹˜: {self.win_path}")
        logger.info("="*70)

#================================================================== 

    def save_to_csv(self, data):
        pd.DataFrame(data).to_csv(self.final_file_path, index=False, encoding="utf-8-sig")

if __name__ == "__main__":
    HeyDealerGradeMapper().run()