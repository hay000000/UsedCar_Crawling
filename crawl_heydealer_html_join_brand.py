#!/usr/bin/env python3
import csv
import time
import requests
from datetime import datetime
from pathlib import Path
from playwright.sync_api import sync_playwright

# --- ì„¤ì • ---
BASE_URL = "https://www.heydealer.com"
BASE_DIR = Path(__file__).resolve().parent
RESULT_DIR = BASE_DIR / "result"
IMG_DIR = BASE_DIR / "image" / "heydealer"

# í´ë” ìƒì„±
RESULT_DIR.mkdir(parents=True, exist_ok=True)
IMG_DIR.mkdir(parents=True, exist_ok=True)
LIST_FILE = RESULT_DIR / "heydealer_list.csv"
DETAIL_FILE = RESULT_DIR / "heydealer_detail.csv"

def load_brand_mapping():
    """result/heydealer_brands_final.csvì—ì„œ ë¸Œëœë“œ ë§¤í•‘ ë°ì´í„° ë¡œë“œ"""
    brand_map = {}
    brand_file = RESULT_DIR / "heydealer_brands_final.csv"
    if brand_file.exists():
        with open(brand_file, "r", encoding="utf-8-sig") as f:
            reader = csv.DictReader(f)
            for row in reader:
                brand_map[row['model_name'].strip()] = {
                    "brand_id": row.get('brand_id', ''),
                    "brand_name": row.get('brand_name', '')
                }
    else:
        print(f"âš ï¸ ë§¤í•‘ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {brand_file}")
    return brand_map

def get_now_times():
    """ë‚ ì§œ í˜•ì‹: 8ìë¦¬, 12ìë¦¬"""
    now = datetime.now()
    return now.strftime("%Y%m%d"), now.strftime("%Y%m%d%H%M")

def save_to_csv_append(file_path, fieldnames, data_dict):
    """ë°ì´í„°ë¥¼ í•œ ì¤„ì”© íŒŒì¼ ëì— ì¦‰ì‹œ ì¶”ê°€"""
    file_exists = Path(file_path).exists()
    with open(file_path, "a", newline="", encoding="utf-8-sig") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames, extrasaction='ignore')
        if not file_exists:
            writer.writeheader()
        writer.writerow(data_dict)

def _extract_card_heydealer(elem, idx, brand_map) -> dict:
    """ëª©ë¡ ì •ë³´ ìˆ˜ì§‘ ë° ì§€ëŠ¥í˜• ë¸Œëœë“œ ë§¤í•‘ (1ì°¨:ì „ì²´, 2ì°¨:ë„ì–´ì“°ê¸° ë’·ë¶€ë¶„)"""
    data = {"model_sn": idx, "brand_id": "", "brand_name": ""}
    try:
        href = elem.get_attribute("href") or ""
        full_url = (BASE_URL + href).split("?")[0] if not href.startswith("http") else href.split("?")[0]
        data["model_cd"] = full_url.split("/")[-1]
        data["detail_url"] = full_url

        m_box = elem.query_selector(".css-9j6363")
        if m_box:
            names = m_box.query_selector_all(".css-jk6asd")
            raw_model_name = names[0].inner_text().strip() if len(names) > 0 else ""
            data["model_name"] = raw_model_name
            data["model_second_name"] = names[1].inner_text().strip() if len(names) > 1 else ""
            
            # --- ì§€ëŠ¥í˜• ë¸Œëœë“œ ë§¤í•‘ ---
            # 1ë‹¨ê³„: ì „ì²´ ì¼ì¹˜ í™•ì¸
            matched = brand_map.get(raw_model_name)
            # 2ë‹¨ê³„: ì‹¤íŒ¨ ì‹œ ì²« ë‹¨ì–´(ë¸Œëœë“œëª…) ë–¼ê³  ë¹„êµ (ì˜ˆ: 'í­ìŠ¤ë°”ê² íŒŒì‚¬íŠ¸' -> 'íŒŒì‚¬íŠ¸')
            if not matched and " " in raw_model_name:
                sub_name = raw_model_name.split(" ", 1)[1].strip()
                matched = brand_map.get(sub_name)
            
            if matched:
                data["brand_id"] = matched["brand_id"]
                data["brand_name"] = matched["brand_name"]

            grade = m_box.query_selector(".css-13wylk3")
            data["grade_name"] = grade.inner_text().strip() if grade else ""

        yk_el = elem.query_selector(".css-6bza35")
        if yk_el:
            txt = yk_el.inner_text().strip()
            if "ã†" in txt:
                p = txt.split("ã†")
                data["year"], data["km"] = p[0].strip(), p[1].strip()
            else: data["year"], data["km"] = txt, ""

        price_area = elem.query_selector(".css-105xtr1 .css-1066lcq .css-dbu2tk")
        if price_area:
            sale = price_area.query_selector(".css-8sjynn")
            data["sale_price"] = sale.inner_text().strip() if sale else price_area.inner_text().strip()

        d_pnttm, c_dt = get_now_times()
        data["date_crtr_pnttm"], data["create_dt"] = d_pnttm, c_dt
    except: pass
    return data

def _extract_detail_smart(page, list_item) -> dict:
    """ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ (ë¼ë²¨ í…ìŠ¤íŠ¸ ë§¤ì¹­: ì™¸ë¶€, ì‹¤ë‚´ ë“±)"""
    res = {
        "model_sn": list_item["model_sn"], "brand_id": list_item["brand_id"], "brand_name": list_item["brand_name"],
        "model_cd": list_item["model_cd"], "model_name": list_item["model_name"],
        "model_second_name": list_item.get("model_second_name", ""), "grade_name": list_item.get("grade_name", ""),
        "year": "", "km": "", "refund": "", "guarantee": "", "accident": "", "inner_car_wash": "", "insurance": "",
        "color_ext": "", "color_int": "", "main_option": "", "delivery_information": "", "rec_reason": "",
        "tire": "", "tinting": "", "car_key": ""
    }
    try:
        page.wait_for_selector(".css-12qft46", timeout=15000)
        # í˜ì´ì§€ ë‚´ ëª¨ë“  ì •ë³´ í•­ëª© íƒìƒ‰
        items = page.query_selector_all(".css-113wzqa")
        for item in items:
            lbl_el = item.query_selector(".css-1b7o1k1")
            val_el = item.query_selector(".css-1b7o1k1 + div")
            if lbl_el and val_el:
                lbl, val = lbl_el.inner_text().strip(), val_el.inner_text().strip()
                if "ì™¸ë¶€" in lbl: res["color_ext"] = val
                elif "ì‹¤ë‚´" in lbl: res["color_int"] = val
                elif "ì—°ì‹" in lbl: res["year"] = val
                elif "ì£¼í–‰ê±°ë¦¬" in lbl: res["km"] = val
                elif "í™˜ë¶ˆ" in lbl: res["refund"] = val
                elif "ë³´ì¦" in lbl: res["guarantee"] = val
                elif "ì‚¬ê³ " in lbl: res["accident"] = val
                elif "ì„¸ì°¨" in lbl: res["inner_car_wash"] = val
                elif "ë³´í—˜" in lbl: res["insurance"] = val
                elif "íƒ€ì´ì–´" in lbl: res["tire"] = val
                elif "í‹´íŒ…" in lbl: res["tinting"] = val
                elif "ì°¨í‚¤" in lbl: res["car_key"] = val

        # ì˜µì…˜ ë° í…ìŠ¤íŠ¸ ë°ì´í„° (íŒŒì´í”„ ì²˜ë¦¬)
        opt_els = page.query_selector_all(".css-5pr39e .css-13wylk3")
        res["main_option"] = ", ".join([o.inner_text().strip() for o in opt_els])
        
        ship_el = page.query_selector(".css-1cfq7ri .css-1n3oo4w")
        if ship_el: res["delivery_information"] = " | ".join([l.strip() for l in ship_el.inner_text().split('\n') if l.strip()])
        
        rec_el = page.query_selector(".css-isc2b5 .css-yfldxx")
        if rec_el: res["rec_reason"] = " | ".join([l.strip() for l in rec_el.inner_text().split('\n') if l.strip()])
    except: pass
    return res

def main():
    # brand_map = load_brand_mapping()
    
    # with sync_playwright() as p:
    #     browser = p.chromium.launch(headless=False)
    #     context = browser.new_context(user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    #     page = context.new_page()
    brand_map = load_brand_mapping()
    list_fields = ["model_sn", "brand_id", "brand_name", "model_cd", "model_name", "model_second_name", "grade_name", "year", "km", "sale_price", "detail_url", "date_crtr_pnttm", "create_dt"]
    detail_fields = ["model_sn", "brand_id", "brand_name", "model_cd", "model_name", "model_second_name", "grade_name", "year", "km", "refund", "guarantee", "accident", "inner_car_wash", "insurance", "color_ext", "color_int", "main_option", "delivery_information", "rec_reason", "tire", "tinting", "car_key", "detail_url", "date_crtr_pnttm", "create_dt"]

    # ê¸°ì¡´ íŒŒì¼ì´ ìˆë‹¤ë©´ ì‚­ì œ (ìƒˆë¡œ ì‹œì‘í•  ë•Œ ì¤‘ë³µ ë°©ì§€)
    for f in [LIST_FILE, DETAIL_FILE]:
        if f.exists(): f.unlink()

    with sync_playwright() as p:
        browser = p.chromium.launch(headless=False)
        context = browser.new_context(user_agent="Mozilla/5.0...")
        page = context.new_page()
        
        print("ğŸš€ í—¤ì´ë”œëŸ¬ ì „ì²´ ëª©ë¡ ìˆ˜ì§‘ ì‹œì‘ (ë¬´ì œí•œ ìŠ¤í¬ë¡¤)...")
        page.goto(f"{BASE_URL}/market/cars", wait_until="networkidle")
        
        raw_list, seen = [], set()
        
        while True:
            prev_count = len(raw_list)
            
            # ëê¹Œì§€ ìŠ¤í¬ë¡¤
            page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
            page.wait_for_timeout(2500) # ë¡œë”© ëŒ€ê¸°
            
            # í˜„ì¬ ë¡œë“œëœ ì¹´ë“œ ìˆ˜ì§‘
            cards = page.query_selector_all('a[href^="/market/cars/"]')
            for card in cards:
                href = card.get_attribute("href").split("?")[0]
                if href not in seen:
                    seen.add(href)
                    item = _extract_card_heydealer(card, len(raw_list) + 1, brand_map)
                    raw_list.append(item)
                    # ëª©ë¡ ì¦‰ì‹œ ì €ì¥
                    save_to_csv_append(LIST_FILE, list_fields, item)

            added = len(raw_list) - prev_count
            print(f" ğŸ”„ ìˆ˜ì§‘: {len(raw_list)}ëŒ€ (ì‹ ê·œ: {added})")
            
            if added == 0:
                no_new_data_count += 1
                print(f" â³ ì¶”ê°€ ì—†ìŒ ({no_new_data_count}/3)")
            else:
                no_new_data_count = 0
            
            if no_new_data_count >= 3: break

        # 2. ìƒì„¸ ìˆ˜ì§‘ ë° ì‹¤ì‹œê°„ ì €ì¥
        print(f"\nğŸš€ [ìƒì„¸ ìˆ˜ì§‘ ì‹œì‘] ì´ {len(raw_list)}ëŒ€ ëŒ€ìƒ")
        for idx, item in enumerate(raw_list, 1):
            print(f" ğŸ” ({idx}/{len(raw_list)}) ìƒì„¸: {item['model_cd']}")
            try:
                page.goto(item["detail_url"], wait_until="networkidle", timeout=40000)
                time.sleep(1.2)
                detail = _extract_detail_smart(page, item)
                detail.update({"detail_url": item["detail_url"], "date_crtr_pnttm": item["date_crtr_pnttm"], "create_dt": item["create_dt"]})
                # ìƒì„¸ ì¦‰ì‹œ ì €ì¥
                save_to_csv_append(DETAIL_FILE, detail_fields, detail)
            except: pass

        print(f"âœ… ì™„ë£Œ! íŒŒì¼ ìœ„ì¹˜: {RESULT_DIR}")
        browser.close()

if __name__ == "__main__":
    main()
            
#             current_count = len(raw_list)
#             print(f" ğŸ”„ ìˆ˜ì§‘ í˜„í™©: {current_count}ëŒ€ (ì¶”ê°€ë¨: {current_count - prev_count})")
            
#             # ì¢…ë£Œ ì¡°ê±´: ìŠ¤í¬ë¡¤ í›„ì—ë„ ê°œìˆ˜ê°€ ëŠ˜ì§€ ì•Šìœ¼ë©´ ì¢…ë£Œ
#             if current_count == prev_count:
#                 print(" â³ ë§ˆì§€ë§‰ í™•ì¸ ì¤‘...")
#                 page.wait_for_timeout(4000)
#                 final_cards = page.query_selector_all('a[href^="/market/cars/"]')
#                 if len(final_cards) <= current_count:
#                     print("âœ… ëª¨ë“  ì°¨ëŸ‰ ëª©ë¡ ë¡œë“œ ì™„ë£Œ.")
#                     break
        
#         # [1] ëª©ë¡ ì €ì¥
#         list_fields = ["model_sn", "brand_id", "brand_name", "model_cd", "model_name", "model_second_name", "grade_name", "year", "km", "sale_price", "detail_url", "date_crtr_pnttm", "create_dt"]
#         with open(RESULT_DIR / "heydealer_list.csv", "w", newline="", encoding="utf-8-sig") as f:
#             writer = csv.DictWriter(f, fieldnames=list_fields, extrasaction='ignore')
#             writer.writeheader()
#             writer.writerows(raw_list)
#         print(f"ğŸ“‚ ëª©ë¡ ì €ì¥ ì™„ë£Œ: {len(raw_list)}ëŒ€")

#         # [2] ìƒì„¸ í˜ì´ì§€ ìˆ˜ì§‘
#         detail_results = []
#         detail_fields = ["model_sn", "brand_id", "brand_name", "model_cd", "model_name", "model_second_name", "grade_name", "year", "km", "refund", "guarantee", "accident", "inner_car_wash", "insurance", "color_ext", "color_int", "main_option", "delivery_information", "rec_reason", "tire", "tinting", "car_key", "detail_url", "date_crtr_pnttm", "create_dt"]

#         for idx, item in enumerate(raw_list, 1):
#             print(f"ğŸ” ìƒì„¸ ìˆ˜ì§‘ ì¤‘ ({idx}/{len(raw_list)}): {item['model_cd']}")
#             try:
#                 page.goto(item["detail_url"], wait_until="networkidle", timeout=40000)
#                 time.sleep(1.5) # ê³¼ë¶€í•˜ ë°©ì§€
#                 detail = _extract_detail_smart(page, item)
#                 detail.update({"detail_url": item["detail_url"], "date_crtr_pnttm": item["date_crtr_pnttm"], "create_dt": item["create_dt"]})
#                 detail_results.append(detail)
#             except Exception as e:
#                 print(f" âš ï¸ {item['model_cd']} ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")

#         with open(RESULT_DIR / "heydealer_detail.csv", "w", newline="", encoding="utf-8-sig") as f:
#             writer = csv.DictWriter(f, fieldnames=detail_fields, extrasaction='ignore')
#             writer.writeheader()
#             writer.writerows(detail_results)
        
#         print("âœ… ëª¨ë“  ë°ì´í„° ìˆ˜ì§‘ ë° ë§¤í•‘ ì™„ë£Œ")
#         browser.close()

# if __name__ == "__main__":
#     main()