#!/usr/bin/env python3
import csv
import logging
import re
import time
import requests
import sys
from datetime import datetime
from pathlib import Path
from playwright.sync_api import sync_playwright

# --- ì„¤ì • ë° ê²½ë¡œ ---
# ----- ëª©ë¡ ìˆ˜ì§‘ ëª¨ë“œ (í…ŒìŠ¤íŠ¸ vs ì „ì²´ ë¬´í•œìŠ¤í¬ë¡¤) -----
# [í…ŒìŠ¤íŠ¸] ëª‡ ê°œë§Œ ìˆ˜ì§‘: TARGET_COUNT = ìˆ«ì (í•´ë‹¹ ê°œìˆ˜ ëª¨ì´ë©´ ìˆ˜ì§‘ ì¢…ë£Œ)
# [ì „ì²´]  ë¬´í•œìŠ¤í¬ë¡¤ ëê¹Œì§€: TARGET_COUNT = None (ìƒˆ ë§¤ë¬¼ ì—†ì„ ë•Œê¹Œì§€ ìŠ¤í¬ë¡¤)
# ì‚¬ìš©ë²•: ë‘˜ ì¤‘ í•˜ë‚˜ë§Œ ìœ ì§€í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” ì£¼ì„ ì²˜ë¦¬
TARGET_COUNT = 5
# TARGET_COUNT = None

BASE_URL = "https://www.heydealer.com"
BASE_DIR = Path(__file__).resolve().parent

# í´ë” ê²½ë¡œ ì„¤ì • (í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€)
# result: csv ì €ì¥
RESULT_DIR = BASE_DIR.parent / "result" / "heydealer"
# logs: ë¡œê·¸ ì €ì¥
LOG_DIR = BASE_DIR.parent / "logs" / "heydealer"
# imgs: ì´ë¯¸ì§€ ë² ì´ìŠ¤ (ì‹¤ì œ ì €ì¥ì€ imgs/heydealer/2026ë…„/20250226/ í˜•íƒœ)
IMG_BASE = BASE_DIR.parent / "imgs" / "heydealer"

# í´ë” ìƒì„±
RESULT_DIR.mkdir(parents=True, exist_ok=True)
LOG_DIR.mkdir(parents=True, exist_ok=True)
IMG_BASE.mkdir(parents=True, exist_ok=True)

# íŒŒì¼ ê²½ë¡œ
LIST_FILE = RESULT_DIR / "heydealer_list.csv"
CAR_TYPE_LIST_FILE = RESULT_DIR / "heydealer_car_type_list.csv"
BRAND_LIST_FILE = RESULT_DIR / "heydealer_brand_list.csv"

# --- ë¡œê·¸ ì„¤ì • ---
LOG_FILE = LOG_DIR / f"heydealer_type_to_list.log"
# ë¸Œëœë“œ ìˆ˜ì§‘ìš©: crawl_heydealer_brand.pyì™€ ë™ì¼í•œ ë¡œê·¸ íŒŒì¼Â·í¬ë§·
BRAND_HIERARCHY_LOG = LOG_DIR / "heydealer_brand_hierarchy.log"
_logger_brand = logging.getLogger("heydealer_brand")
_logger_brand.setLevel(logging.INFO)
_logger_brand.handlers.clear()
_fmt = logging.Formatter("%(asctime)s - %(levelname)s - %(message)s")
_h_file = logging.FileHandler(BRAND_HIERARCHY_LOG, encoding="utf-8")
_h_file.setFormatter(_fmt)
_h_stream = logging.StreamHandler()
_h_stream.setFormatter(_fmt)
_logger_brand.addHandler(_h_file)
_logger_brand.addHandler(_h_stream)

class Logger(object):
    def __init__(self):
        self.terminal = sys.stdout
        self.log = open(LOG_FILE, "a", encoding="utf-8")
    def write(self, message):
        self.terminal.write(message)
        self.log.write(message)
    def flush(self):
        self.terminal.flush()
        self.log.flush()

sys.stdout = Logger()

_today_img_dir = IMG_BASE / f"{datetime.now().strftime('%Y')}ë…„" / datetime.now().strftime("%Y%m%d")
print(f"[{datetime.now()}] ğŸ í—¤ì´ë”œëŸ¬ ìˆ˜ì§‘ í”„ë¡œê·¸ë¨ ì‹œì‘")
print(f"ğŸ“ ì´ë¯¸ì§€ ì €ì¥ ê²½ë¡œ: {_today_img_dir}")

BRAND_CSV_FIELDS = [
    "brand_id", "brand_name", "model_group_id", "model_group_name",
    "model_id", "model_name", "production_period", "data_crtr_pnttm", "create_dt"
]

def fetch_and_save_brand_csv():
    """crawl_heydealer_brand.pyì™€ ë™ì¼: APIë¡œ ë¸Œëœë“œÂ·ëª¨ë¸ ê³„ì¸µ ìˆ˜ì§‘ í›„ brand CSV ì €ì¥. ë¡œê·¸ëŠ” heydealer_brand_hierarchy.log ì‚¬ìš©."""
    log = _logger_brand
    if BRAND_LIST_FILE.exists():
        BRAND_LIST_FILE.unlink()
    API_BASE = "https://api.heydealer.com/v2/customers/web/market/car_meta"
    session = requests.Session()
    session.headers.update({
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
        "Accept": "application/json",
    })
    d_pnttm = datetime.now().strftime("%Y%m%d")
    c_dt = datetime.now().strftime("%Y%m%d%H%M")
    n_written = 0
    try:
        log.info("=" * 60)
        log.info("í—¤ì´ë”œëŸ¬ ë¸Œëœë“œ-ëª¨ë¸ ê³„ì¸µ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ (ë‚ ì§œ ì •ë³´ í¬í•¨)")
        log.info("=" * 60)
        brands_resp = session.get(f"{API_BASE}/brands/", timeout=15)
        brands_resp.raise_for_status()
        raw = brands_resp.json()
        brands = raw if isinstance(raw, list) else (raw.get("brands") or raw.get("data") or []) if isinstance(raw, dict) else []
        n_brands = len(brands)
        log.info(f"ì´ {n_brands}ê°œ ë¸Œëœë“œ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
        for b_idx, brand in enumerate(brands, 1):
            brand_id = brand.get("hash_id")
            brand_name = brand.get("name")
            log.info(f"[{b_idx}/{n_brands}] ë¸Œëœë“œ ì²˜ë¦¬ ì¤‘: {brand_name}")
            mg_resp = session.get(f"{API_BASE}/brands/{brand_id}/", timeout=15)
            if mg_resp.status_code != 200:
                continue
            for mg in mg_resp.json().get("model_groups", []):
                mg_id = mg.get("hash_id")
                mg_name = mg.get("name")
                sub_resp = session.get(f"{API_BASE}/model_groups/{mg_id}/", timeout=15)
                if sub_resp.status_code != 200:
                    continue
                for model in sub_resp.json().get("models", []):
                    row = {
                        "brand_id": brand_id,
                        "brand_name": brand_name,
                        "model_group_id": mg_id,
                        "model_group_name": mg_name,
                        "model_id": model.get("hash_id", ""),
                        "model_name": model.get("name", ""),
                        "production_period": model.get("period", ""),
                        "data_crtr_pnttm": d_pnttm,
                        "create_dt": c_dt,
                    }
                    save_to_csv_append(BRAND_LIST_FILE, BRAND_CSV_FIELDS, row)
                    n_written += 1
                time.sleep(0.1)
        if n_written:
            log.info("=" * 60)
            log.info(f"âœ… ìˆ˜ì§‘ ì™„ë£Œ! íŒŒì¼: {BRAND_LIST_FILE}")
            log.info(f"ì´ ìˆ˜ì§‘ ëª¨ë¸ ìˆ˜: {n_written:,}ê°œ")
            log.info("=" * 60)
        else:
            log.warning("âš ï¸ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    except Exception as e:
        log.error(f"âŒ í¬ë¡¤ë§ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()

def load_brand_mapping():
    """model_name(ì •í™•) -> {brand_id, brand_name}, brand_name(ë¸Œëœë“œëª…) -> {brand_id, brand_name} ë‘˜ ë‹¤ ë°˜í™˜."""
    brand_map = {}
    brand_by_name = {}
    if BRAND_LIST_FILE.exists():
        with open(BRAND_LIST_FILE, "r", encoding="utf-8-sig") as f:
            reader = csv.DictReader(f)
            for row in reader:
                info = {"brand_id": row.get("brand_id", ""), "brand_name": row.get("brand_name", "").strip()}
                model_name = (row.get("model_name") or "").strip()
                if model_name:
                    brand_map[model_name] = info
                bn = info["brand_name"]
                if bn and bn not in brand_by_name:
                    brand_by_name[bn] = info
    else:
        print(f"âš ï¸ ë§¤í•‘ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {BRAND_LIST_FILE}")
    return brand_map, brand_by_name

def get_now_times():
    now = datetime.now()
    return now.strftime("%Y%m%d"), now.strftime("%Y%m%d%H%M")

def save_to_csv_append(file_path, fieldnames, data_dict):
    file_exists = Path(file_path).exists()
    with open(file_path, "a", newline="", encoding="utf-8-sig") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames, extrasaction='ignore')
        if not file_exists:
            writer.writeheader()
        writer.writerow(data_dict)

def download_image(img_url, model_cd, idx):
    """ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ. ì €ì¥ ê²½ë¡œ: imgs/heydealer/ì—°ë„/YYYYMMDD/model_cd_idx.ext"""
    try:
        if not img_url or "svg" in img_url.lower():
            return False
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
            "Referer": BASE_URL,
        }
        response = requests.get(img_url, stream=True, timeout=15, headers=headers)
        if response.status_code != 200:
            return False
        ext = img_url.split(".")[-1].split("?")[0].lower()
        if len(ext) > 4 or len(ext) < 2:
            ext = "jpg"
        now = datetime.now()
        save_dir = IMG_BASE / f"{now.strftime('%Y')}ë…„" / now.strftime("%Y%m%d")
        save_dir.mkdir(parents=True, exist_ok=True)
        filename = f"{model_cd}_{idx}.{ext}"
        save_path = save_dir / filename
        with open(save_path, "wb") as f:
            for chunk in response.iter_content(1024):
                f.write(chunk)
        return True
    except Exception:
        return False

def _collect_images_from_detail_page(page, model_cd):
    """ìƒì„¸ í˜ì´ì§€ì—ì„œ ì´ë¯¸ì§€ë§Œ ìˆ˜ì§‘Â·ì €ì¥ (list_detail_brandì™€ ë™ì¼ ë¡œì§, detail CSV ì—†ìŒ)."""
    downloaded_urls = set()
    img_idx = 1
    try:
        try:
            page.wait_for_selector(".css-12qft46", timeout=20000)
        except Exception:
            try:
                page.wait_for_selector(".css-113wzqa", timeout=10000)
            except Exception:
                pass
        page.wait_for_timeout(2000)
        for i in range(1, 14):
            page.evaluate(f"window.scrollTo(0, {i * 500})")
            time.sleep(0.15)
        page.evaluate("window.scrollTo(0, 0)")
        page.wait_for_timeout(800)
        detail_container = page.query_selector(".css-1uus6sd .css-12qft46")
        if not detail_container:
            detail_container = page.query_selector(".css-12qft46")
        if detail_container:
            ltrevz_sections = detail_container.query_selector_all(".css-ltrevz")
            if len(ltrevz_sections) >= 2:
                sec2 = ltrevz_sections[1]
                for sel in [".css-5pr39e .css-1i3qy3r .css-1dpi6xl button.css-q47uzu img.css-q38rgl", "button.css-q47uzu img.css-q38rgl", "button img, .css-q47uzu img"]:
                    imgs = sec2.query_selector_all(sel)
                    if imgs:
                        for img in imgs:
                            src = img.get_attribute("src") or img.get_attribute("data-src")
                            if src and src not in downloaded_urls and "svg" not in src.lower():
                                if download_image(src, model_cd, img_idx):
                                    downloaded_urls.add(src)
                                    img_idx += 1
                        break
            if len(ltrevz_sections) >= 4:
                sec4 = ltrevz_sections[3]
                for sel in [".css-5pr39e .css-1i3qy3r .css-hf19cn .css-1a3591h img.css-158t7i4", ".css-5pr39e .css-1i3qy3r .css-w9nhgi img.css-158t7i4", ".css-hf19cn .css-1a3591h img", ".css-hf19cn .css-w9nhgi img", ".css-w9nhgi img.css-158t7i4"]:
                    for img in sec4.query_selector_all(sel):
                        src = img.get_attribute("src") or img.get_attribute("data-src")
                        if src and src not in downloaded_urls and "svg" not in src.lower():
                            if download_image(src, model_cd, img_idx):
                                downloaded_urls.add(src)
                                img_idx += 1
        if img_idx == 1:
            fallback_imgs = page.query_selector_all("img[src*='heydealer.com'], img[src*='cdn.'], .css-w9nhgi img, .css-1a3591h img, main img")
            for img in fallback_imgs:
                src = img.get_attribute("src") or img.get_attribute("data-src")
                if not src or "svg" in src.lower() or src in downloaded_urls:
                    continue
                if download_image(src, model_cd, img_idx):
                    downloaded_urls.add(src)
                    img_idx += 1
        if img_idx == 1:
            page.wait_for_timeout(2000)
            for i in range(1, 12):
                page.evaluate(f"window.scrollTo(0, {i * 600})")
                time.sleep(0.2)
            for img in page.query_selector_all("img[src], img[data-src]"):
                src = img.get_attribute("src") or img.get_attribute("data-src")
                if not src or "svg" in src.lower() or src in downloaded_urls:
                    continue
                if "heydealer" in src or "cdn." in src or len(src) > 20:
                    if download_image(src, model_cd, img_idx):
                        downloaded_urls.add(src)
                        img_idx += 1
    except Exception as e:
        print(f"      âŒ ì´ë¯¸ì§€ ìˆ˜ì§‘ ì˜¤ë¥˜ ({model_cd}): {str(e)[:60]}")
    return img_idx - 1

def _extract_card_heydealer(elem, idx, brand_map, car_type="", brand_by_name=None) -> dict:
    data = {"model_sn": idx, "brand_id": "", "brand_name": "", "car_type": car_type}
    try:
        href = elem.get_attribute("href") or ""
        full_url = (BASE_URL + href).split("?")[0] if not href.startswith("http") else href.split("?")[0]
        data["model_cd"] = full_url.split("/")[-1]
        data["detail_url"] = full_url
        m_box = elem.query_selector(".css-9j6363")
        if m_box:
            names = m_box.query_selector_all(".css-jk6asd")
            raw_model_name = names[0].inner_text().strip() if len(names) > 0 else ""
            data["model_name"] = raw_model_name
            data["model_second_name"] = names[1].inner_text().strip() if len(names) > 1 else ""
            matched = brand_map.get(raw_model_name)
            if not matched and " " in raw_model_name:
                sub_name = raw_model_name.split(" ", 1)[1].strip()
                matched = brand_map.get(sub_name)
            if not matched and brand_by_name:
                for word in raw_model_name.replace("Â·", " ").split():
                    w = word.strip()
                    if w and brand_by_name.get(w):
                        matched = brand_by_name[w]
                        break
            if matched:
                data["brand_id"], data["brand_name"] = matched["brand_id"], matched["brand_name"]
            grade = m_box.query_selector(".css-13wylk3")
            data["grade_name"] = grade.inner_text().strip() if grade else ""
        yk_el = elem.query_selector(".css-6bza35")
        if yk_el:
            txt = yk_el.inner_text().strip()
            if "ã†" in txt:
                p = txt.split("ã†")
                data["year"], data["km"] = p[0].strip(), p[1].strip()
            else: data["year"], data["km"] = txt, ""
        price_area = elem.query_selector(".css-105xtr1 .css-1066lcq .css-dbu2tk")
        if price_area:
            sale = price_area.query_selector(".css-8sjynn")
            data["sale_price"] = sale.inner_text().strip() if sale else price_area.inner_text().strip()
        d_pnttm, c_dt = get_now_times()
        data["date_crtr_pnttm"], data["create_dt"] = d_pnttm, c_dt
    except: pass
    return data

def main():
    print(f"\nğŸ“„ [0ë‹¨ê³„] ë¸Œëœë“œ API ìˆ˜ì§‘ â†’ heydealer_brand_list.csv ìƒì„±")
    fetch_and_save_brand_csv()
    brand_map, brand_by_name = load_brand_mapping()
    list_fields = ["model_sn", "brand_id", "brand_name", "model_cd", "model_name", "model_second_name", "grade_name", "car_type", "year", "km", "sale_price", "detail_url", "date_crtr_pnttm", "create_dt"]

    if LIST_FILE.exists():
        LIST_FILE.unlink()
    if CAR_TYPE_LIST_FILE.exists():
        CAR_TYPE_LIST_FILE.unlink()

    print(f"\nğŸš€ [1ë‹¨ê³„] ëª©ë¡ ìˆ˜ì§‘ì„ ìœ„í•´ ë¸Œë¼ìš°ì €ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤...")
    sys.stdout.flush()
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=False)
        context = browser.new_context(
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
            viewport={'width': 1920, 'height': 1080}
        )
        page = context.new_page()
        page.add_init_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
        
        # í…ŒìŠ¤íŠ¸(TARGET_COUNT ìˆ«ì) vs ì „ì²´(TARGET_COUNT=None) ì— ë”°ë¼ ë©”ì‹œì§€ ë¶„ê¸°
        if TARGET_COUNT is not None:
            print(f"\nğŸš€ [1ë‹¨ê³„] ëª©ë¡ ìˆ˜ì§‘ ì‹œì‘ (í…ŒìŠ¤íŠ¸: ëª©í‘œ {TARGET_COUNT}ê°œ)")
        else:
            print(f"\nğŸš€ [1ë‹¨ê³„] ëª©ë¡ ìˆ˜ì§‘ ì‹œì‘ (ì „ì²´: ë¬´í•œìŠ¤í¬ë¡¤ ëê¹Œì§€)")
        list_url = f"{BASE_URL}/market/cars"
        for nav_try in range(3):
            try:
                page.goto(list_url, wait_until="commit", timeout=60000)
                page.wait_for_load_state("domcontentloaded", timeout=15000)
                break
            except Exception as e:
                if nav_try < 2:
                    print(f"   âš ï¸ ëª©ë¡ í˜ì´ì§€ ì¬ì‹œë„ ({nav_try + 2}/3)...")
                    time.sleep(3)
                else:
                    raise RuntimeError(f"ëª©ë¡ í˜ì´ì§€ ì ‘ì† ì‹¤íŒ¨: {list_url}") from e
        page.wait_for_timeout(3000)

        # ----- ì°¨ì²´: í´ë˜ìŠ¤ëª… ì—†ì´ í…ìŠ¤íŠ¸Â·êµ¬ì¡°ë§Œ ì‚¬ìš© (í´ë˜ìŠ¤ ë³€ê²½ì— ê°•í•¨) -----
        # íë¦„: [1] ì°¨ì²´ íƒ­ í´ë¦­ â†’ ì˜¤ë²„ë ˆì´ì—ì„œ ì°¨ì¢… ë²„íŠ¼(ê²½âˆ™ì†Œí˜•, ì„¸ë‹¨ ë“±) í…ìŠ¤íŠ¸ë¡œ ì°¾ê¸° â†’ ì„ íƒ â†’ NëŒ€ ë³´ê¸° â†’ ëª©ë¡ ìˆ˜ì§‘
        # ì •ê·œí™” í›„ ë¹„êµìš© (ì¤‘ì Â·ê³µë°± í‘œê¸° ì°¨ì´ ë¬´ì‹œ: SUV Â· RV, SUVâˆ™RV, ê²½ Â· ì†Œí˜• ë“±)
        CANONICAL_CAR_BODY = {"ê²½âˆ™ì†Œí˜•", "ì„¸ë‹¨", "SUVâˆ™RV", "ì¿ í˜", "ë¦¬ë¬´ì§„", "ì»¨ë²„í„°ë¸”", "í•´ì¹˜ë°±"}

        def _normalize_car_label(txt):
            """ì°¨ì¢… í…ìŠ¤íŠ¸ ì •ê·œí™”: ê³µë°±Â·ë‹¤ì–‘í•œ ì¤‘ì (Â·âˆ™) í†µì¼ í›„ ë¹„êµ"""
            if not txt:
                return ""
            s = (txt or "").strip()
            s = re.sub(r"\s*[Â·âˆ™]\s*", "âˆ™", s)  # ' Â· ' / 'âˆ™' -> 'âˆ™'
            s = re.sub(r"\s+", " ", s).strip()
            return s

        def _open_car_body_panel():
            """ì°¨ì²´ íƒ­: í…ìŠ¤íŠ¸ 'ì°¨ì²´'ì¸ ë²„íŠ¼ í´ë¦­ (í´ë˜ìŠ¤ ë¬´ê´€)"""
            tab = page.get_by_role("button", name="ì°¨ì²´")
            if tab.count() == 0:
                tab = page.locator("#root button").filter(has_text=re.compile(r"^ì°¨ì²´$"))
            if tab.count() == 0:
                # í´ë°±: í•„í„° ì˜ì—­ 6ë²ˆì§¸ ë²„íŠ¼ (ì°¨ì²´ê°€ 6ë²ˆì§¸ì¸ ê²½ìš°)
                tab = page.locator("#root button[type='button']").nth(5)
            if tab.count() > 0:
                tab.first.scroll_into_view_if_needed()
                tab.first.click(force=True)
                page.wait_for_timeout(600)

        def _get_car_body_overlay():
            """ì°¨ì²´ ì˜¤ë²„ë ˆì´: 'ì°¨ì²´' ë¬¸êµ¬ì™€ 'NëŒ€ ë³´ê¸°' ë²„íŠ¼ì´ í•¨ê»˜ ìˆëŠ” ì»¨í…Œì´ë„ˆ (í´ë˜ìŠ¤ ë¬´ê´€)"""
            overlay = page.locator("div").filter(
                has=page.locator("button").filter(has_text=re.compile(r"[\d,]+ëŒ€\s*ë³´ê¸°"))
            ).filter(has=page.get_by_text("ì°¨ì²´"))
            return overlay.first

        def _get_car_type_labels_from_overlay(overlay):
            """ì˜¤ë²„ë ˆì´ ì•ˆì—ì„œ ì°¨ì¢… ë²„íŠ¼ í…ìŠ¤íŠ¸ë§Œ ìˆ˜ì§‘ (ìˆœì„œ ìœ ì§€). ì •ê·œí™” í›„ CANONICALê³¼ ë§¤ì¹­, í´ë¦­ìš©ìœ¼ë¡œëŠ” í˜ì´ì§€ì˜ ì‹¤ì œ í…ìŠ¤íŠ¸ ì‚¬ìš©."""
            labels = []
            try:
                for node in overlay.locator("button").all():
                    raw = (node.inner_text() or "").strip()
                    if not raw or re.match(r"[\d,]+ëŒ€\s*ë³´ê¸°", raw) or raw == "ì´ˆê¸°í™”":
                        continue
                    canonical = _normalize_car_label(raw)
                    if canonical in CANONICAL_CAR_BODY:
                        labels.append(raw)
            except Exception:
                pass
            return labels

        _open_car_body_panel()
        page.wait_for_timeout(1500)
        car_type_entries = []
        try:
            for _ in range(2):
                overlay = _get_car_body_overlay()
                if overlay.count() > 0:
                    car_type_labels = _get_car_type_labels_from_overlay(overlay)
                    if car_type_labels:
                        car_type_entries = list(enumerate(car_type_labels))
                        break
                page.wait_for_timeout(1200)
            if not car_type_entries:
                page.keyboard.press("Escape")
                page.wait_for_timeout(1000)
                car_type_entries = [(0, "")]
            else:
                print(f" ğŸ“Œ ì°¨ì¢…(ì°¨ì²´) {len(car_type_entries)}ê°œ (í…ìŠ¤íŠ¸ ê¸°ì¤€): {[lbl for _, lbl in car_type_entries]}")
                for sn, (_, car_type_name) in enumerate(car_type_entries, 1):
                    save_to_csv_append(CAR_TYPE_LIST_FILE, ["car_type_sn", "car_type_name"], {"car_type_sn": sn, "car_type_name": car_type_name})
                print(f" ğŸ“„ ì°¨ì¢… ëª©ë¡ ì €ì¥: {CAR_TYPE_LIST_FILE}")
                page.keyboard.press("Escape")
                page.wait_for_timeout(1000)
        except Exception as e:
            print(f"   âš ï¸ ì°¨ì²´ ì˜µì…˜ ì½ê¸° ì‹¤íŒ¨: {e}")
            car_type_entries = [(0, "")]

        raw_list, seen = [], set()

        for entry_idx, (car_type_idx, current_car_type) in enumerate(car_type_entries):
            collected_this_type = 0
            prev_count = len(raw_list)
            no_new_rounds = 0
            if len(car_type_entries) > 1:
                select_ok = False
                for _attempt in range(2):
                    try:
                        if _attempt > 0:
                            page.keyboard.press("Escape")
                            page.wait_for_timeout(800)
                        _open_car_body_panel()
                        page.wait_for_timeout(700)
                        overlay = _get_car_body_overlay()
                        if overlay.count() == 0:
                            raise RuntimeError("ì°¨ì²´ ì˜¤ë²„ë ˆì´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                        # ì´ì „ ì°¨ì¢… í•´ì œ í›„ í˜„ì¬ ì°¨ì¢… ì„ íƒ (í…ìŠ¤íŠ¸ë¡œ ë²„íŠ¼ ì°¾ê¸°)
                        if entry_idx > 0:
                            prev_label = car_type_entries[entry_idx - 1][1]
                            prev_btn = overlay.locator("button").filter(has_text=re.compile(re.escape(prev_label)))
                            if prev_btn.count() > 0:
                                prev_btn.first.scroll_into_view_if_needed()
                                prev_btn.first.click(force=True)
                                page.wait_for_timeout(400)
                        btn = overlay.locator("button").filter(has_text=re.compile(re.escape(current_car_type)))
                        if btn.count() == 0:
                            print(f"   âš ï¸ [{current_car_type}] ì°¨ì¢… ë²„íŠ¼ ì—†ìŒ, ê±´ë„ˆëœ€")
                            break
                        btn.first.scroll_into_view_if_needed()
                        page.wait_for_timeout(200)
                        btn.first.click(force=True)
                        page.wait_for_timeout(600)
                        view_btn = overlay.locator("button").filter(has_text=re.compile(r"[\d,]+ëŒ€\s*ë³´ê¸°"))
                        if view_btn.count() > 0:
                            view_btn.first.click()
                            page.wait_for_timeout(2500)
                        else:
                            page.wait_for_timeout(1500)
                        print(f" ğŸ”˜ ì°¨ì¢… ì„ íƒÂ·ì ìš©: {current_car_type} â†’ ëª©ë¡ ìˆ˜ì§‘ ì‹œì‘")
                        select_ok = True
                        break
                    except Exception as e:
                        print(f"   âš ï¸ ì°¨ì¢… ì„ íƒ/ë³´ê¸° ì‹¤íŒ¨ ({current_car_type}), ì¬ì‹œë„ ì˜ˆì •: {e}")
                if not select_ok:
                    continue

            # 5) ì ìš©ëœ ì°¨ì¢… ëª©ë¡ë§Œ ë¬´í•œ ìŠ¤í¬ë¡¤ë¡œ ìˆ˜ì§‘ (í…ŒìŠ¤íŠ¸ ì‹œ ì´ ì°¨ì¢…ì—ì„œ TARGET_COUNTê°œë§Œ, ì „ì²´ ì‹œ ëê¹Œì§€)
            while True:
                if TARGET_COUNT is not None and collected_this_type >= TARGET_COUNT:
                    print(f" âœ… [{current_car_type}] ëª©í‘œ {TARGET_COUNT}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")
                    break

                prev_collected_this_type = collected_this_type
                last_height = page.evaluate("document.body.scrollHeight")
                page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
                page.wait_for_timeout(2500)

                cards = page.query_selector_all('a[href^="/market/cars/"]')
                for card in cards:
                    if TARGET_COUNT is not None and collected_this_type >= TARGET_COUNT:
                        break

                    href = (card.get_attribute("href") or "").split("?")[0]
                    if href and href not in seen:
                        seen.add(href)
                        item = _extract_card_heydealer(card, len(raw_list) + 1, brand_map, car_type=current_car_type, brand_by_name=brand_by_name)
                        raw_list.append(item)
                        save_to_csv_append(LIST_FILE, list_fields, item)
                        collected_this_type += 1

                if collected_this_type == prev_collected_this_type:
                    no_new_rounds += 1
                else:
                    no_new_rounds = 0
                prev_count = len(raw_list)

                if TARGET_COUNT is not None:
                    print(f" ğŸ”„ ëª©ë¡ ìˆ˜ì§‘ [{current_car_type}]: {collected_this_type}/{TARGET_COUNT}ëŒ€ (ì´ {len(raw_list)}ëŒ€)")
                else:
                    print(f" ğŸ”„ ëª©ë¡ ìˆ˜ì§‘ [{current_car_type}]: {collected_this_type}ëŒ€ (ì´ {len(raw_list)}ëŒ€)")

                new_height = page.evaluate("document.body.scrollHeight")
                if new_height == last_height:
                    page.wait_for_timeout(2000)
                    if page.evaluate("document.body.scrollHeight") == last_height:
                        print(f"ğŸ í˜ì´ì§€ ë ë„ë‹¬ (ì´ {len(raw_list)}ëŒ€)")
                        break
                else:
                    no_new_rounds = 0
                if no_new_rounds >= 2:
                    print(f"ğŸ ìƒˆ ë§¤ë¬¼ ì—†ìŒ, ìˆ˜ì§‘ ì¢…ë£Œ (ì´ {len(raw_list)}ëŒ€)")
                    break

        print(f"\nğŸ“„ ëª©ë¡ CSV ìƒì„± ì™„ë£Œ: {LIST_FILE} ({len(raw_list)}ê±´)")
        img_total = 0
        if len(raw_list) > 0:
            print(f"\nğŸš€ [2ë‹¨ê³„] ìƒì„¸ í˜ì´ì§€ ì´ë¯¸ì§€ ìˆ˜ì§‘")
            for idx, item in enumerate(raw_list, 1):
                model_cd = item.get("model_cd", "")
                detail_url = item.get("detail_url", "")
                if not detail_url:
                    continue
                for retry in range(3):
                    try:
                        print(f"   ğŸ“· ({idx}/{len(raw_list)}) {model_cd}")
                        page.goto(detail_url, wait_until="domcontentloaded", timeout=40000)
                        page.wait_for_load_state("load", timeout=15000)
                        page.wait_for_timeout(1500)
                        n_img = _collect_images_from_detail_page(page, model_cd)
                        img_total += n_img
                        break
                    except Exception as e:
                        if retry < 2:
                            time.sleep(2)
                        else:
                            print(f"      âš ï¸ ê±´ë„ˆëœ€: {str(e)[:50]}")
            _img_dir = IMG_BASE / f"{datetime.now().strftime('%Y')}ë…„" / datetime.now().strftime("%Y%m%d")
            print(f"\nğŸ“· ì´ë¯¸ì§€ ìˆ˜ì§‘ ì™„ë£Œ: {img_total}ì¥ â†’ {_img_dir}")
        print(f"\n[{datetime.now()}] âœ… ì‘ì—… ì™„ë£Œ (brand + car_type + list + ì´ë¯¸ì§€)")
        print(f"   - brand.csv:   {BRAND_LIST_FILE}")
        print(f"   - car_type.csv: {CAR_TYPE_LIST_FILE}")
        print(f"   - list.csv:    {LIST_FILE} ({len(raw_list)}ê±´)")
        print(f"   - ì´ë¯¸ì§€:      {img_total}ì¥ â†’ {IMG_BASE}/ì—°ë„/ë‚ ì§œ/")
        print(f"   - ê²°ê³¼ í´ë”:   {RESULT_DIR}")
        print(f"   - ë¡œê·¸:        {LOG_FILE}")

        browser.close()

if __name__ == "__main__":
    main()