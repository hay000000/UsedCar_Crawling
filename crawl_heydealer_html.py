#!/usr/bin/env python3
import csv
import time
import requests
from datetime import datetime
from pathlib import Path
from playwright.sync_api import sync_playwright

# --- ì„¤ì • ---
TEST_LIMIT = 10 
BASE_URL = "https://www.heydealer.com"
BASE_DIR = Path(__file__).resolve().parent
RESULT_DIR = BASE_DIR / "result"
IMG_DIR = BASE_DIR / "image" / "heydealer"

RESULT_DIR.mkdir(parents=True, exist_ok=True)
IMG_DIR.mkdir(parents=True, exist_ok=True)

def get_now_times():
    """ìš”ì²­í•˜ì‹  í˜•ì‹ì˜ ë‚ ì§œ ë°ì´í„° ìƒì„±"""
    now = datetime.now()
    # 202602111328 í˜•ì‹ (YYYYMMDDHHMI) - 12ìë¦¬
    creat_de = now.strftime("%Y%m%d%H%M")
    # 20260211 í˜•ì‹ (YYYYMMDD) - 8ìë¦¬
    data_crtr_pnttm = now.strftime("%Y%m%d")
    return data_crtr_pnttm, creat_de

def download_image(img_url, model_cd, idx):
    """ì´ë¯¸ì§€ë¥¼ ë¡œì»¬ ./image/heydealer í´ë”ì— ì €ì¥"""
    try:
        if not img_url: return
        response = requests.get(img_url, stream=True, timeout=10)
        if response.status_code == 200:
            ext = img_url.split('.')[-1].split('?')[0]
            filename = f"{model_cd}_{idx}.{ext}"
            save_path = IMG_DIR / filename
            with open(save_path, 'wb') as f:
                for chunk in response.iter_content(1024):
                    f.write(chunk)
    except:
        pass

def _extract_card_heydealer(elem, idx) -> dict:
    """ëª©ë¡ ì •ë³´ ìˆ˜ì§‘"""
    data = {"model_sn": idx}
    try:
        href = elem.get_attribute("href") or ""
        full_url = (BASE_URL + href).split("?")[0] if not href.startswith("http") else href.split("?")[0]
        data["model_cd"] = full_url.split("/")[-1]
        data["detail_url"] = full_url

        m_box = elem.query_selector(".css-9j6363")
        if m_box:
            names = m_box.query_selector_all(".css-jk6asd")
            data["model_name"] = names[0].inner_text().strip() if len(names) > 0 else ""
            data["model_second_name"] = names[1].inner_text().strip() if len(names) > 1 else ""
            grade = m_box.query_selector(".css-13wylk3")
            data["grade_name"] = grade.inner_text().strip() if grade else ""

        yk_el = elem.query_selector(".css-6bza35")
        if yk_el:
            txt = yk_el.inner_text().strip()
            if "ã†" in txt:
                p = txt.split("ã†")
                data["year"], data["km"] = p[0].strip(), p[1].strip()
            else: data["year"], data["km"] = txt, ""

        price_area = elem.query_selector(".css-105xtr1 .css-1066lcq .css-dbu2tk")
        if price_area:
            before = price_area.query_selector(".css-ja3yiu")
            sale = price_area.query_selector(".css-8sjynn")
            data["before_sale"] = before.inner_text().strip() if before else ""
            data["sale_price"] = sale.inner_text().strip() if sale else price_area.inner_text().strip()

        nc_el = elem.query_selector(".css-o11ltr")
        data["new_car_price"] = nc_el.inner_text().strip() if nc_el else ""

        info_tags = elem.query_selector_all(".css-14xsjnu .css-nzdaom")
        data["accident"] = info_tags[0].inner_text().strip() if len(info_tags) > 0 else ""
        data["insurance"] = info_tags[1].inner_text().strip() if len(info_tags) > 1 else ""

        # ë‚ ì§œ ì •ë³´ ì¶”ê°€
        d_pnttm, c_dt = get_now_times()
        data["date_crtr_pnttm"] = d_pnttm
        data["create_dt"] = c_dt
    except: pass
    return data

def clean_text_to_pipe(raw_text):
    """ì˜¤ì§ ì¤„ë°”ê¿ˆë§Œ íŒŒì´í”„ë¡œ ë³€ê²½í•˜ì—¬ ì›ë³¸ ë°ì´í„° ë³´ì¡´"""
    if not raw_text: return ""
    # ì¤„ë°”ê¿ˆì„ ê¸°ì¤€ìœ¼ë¡œ ë‚˜ëˆ„ê³ , ê° ì¤„ì˜ ì•ë’¤ ê³µë°±ë§Œ ì œê±°í•œ ë’¤ íŒŒì´í”„ë¡œ ì—°ê²°
    lines = [line.strip() for line in raw_text.split('\n') if line.strip()]
    return " | ".join(lines)

def _extract_detail_smart(page, idx, model_cd) -> dict:
    """ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ - ìš”ì²­í•˜ì‹  2ê°œ ì»¬ëŸ¼ë§Œ íŒŒì´í”„ ì ìš©"""
    res = {"model_sn": idx, "model_cd": model_cd}
    try:
        page.wait_for_selector(".css-12qft46", timeout=15000)
        container = page.query_selector(".css-1uus6sd .css-12qft46")
        if not container: return res
            
        sections = container.query_selector_all(".css-ltrevz")
        
        # --- [ì„¹ì…˜ 1] ì°¨ëŸ‰ëª… ë° ê¸°ë³¸ ìŠ¤í™ ---
        # --- [ì„¹ì…˜ 1] ì´ë¦„ ë° year ~ insurance ì˜ì—­ ---
        if len(sections) >= 1:
            sec1 = sections[0]
            m_name_el = sec1.query_selector(".css-1ugrlhy")
            res["model_name"] = m_name_el.inner_text().strip() if m_name_el else ""
            spans = sec1.query_selector_all(".css-pjgjzs span")
            v_spans = [s.inner_text().strip() for s in spans if s.inner_text().strip()]
            if len(v_spans) == 1: res["grade_name"] = v_spans[0]
            elif len(v_spans) >= 2: res["model_second_name"], res["grade_name"] = v_spans[0], v_spans[1]

            keys = ["year", "km", "refund", "guarantee", "accident", "inner_car_wash", "insurance"]


            # [í•µì‹¬] í…ìŠ¤íŠ¸ ë§¤ì¹­ ë¡œì§: ì¸ë±ìŠ¤ê°€ ì•„ë‹ˆë¼ 'ì—°ì‹', 'ì£¼í–‰ê±°ë¦¬'ë¼ëŠ” ê¸€ìë¥¼ ë³´ê³  ì €ì¥í•¨
            # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ í•´ë‹¹ ifë¬¸ì— ì•ˆ ê±¸ë¦¬ë¯€ë¡œ ê·¸ëƒ¥ ë¹ˆê°’("")ìœ¼ë¡œ ë‚¨ìŒ (ë°€ë¦¼ ë°©ì§€)
            items = sec1.query_selector_all(".css-113wzqa")
            for item in items:
                label_el = item.query_selector(".css-1b7o1k1") # 'ì—°ì‹', 'ì£¼í–‰ê±°ë¦¬' ë“±ì´ ì íŒ ê³³
                val_el = item.query_selector(".css-1b7o1k1 + div") # ì‹¤ì œ ë°ì´í„°ê°€ ì íŒ ê³³
                
                if label_el and val_el:
                    label = label_el.inner_text().strip()
                    value = val_el.inner_text().strip()
                    
                    if "ì—°ì‹" in label: res["year"] = value
                    elif "ì£¼í–‰ê±°ë¦¬" in label: res["km"] = value
                    elif "í™˜ë¶ˆ" in label: res["refund"] = value
                    elif "ë³´ì¦" in label: res["guarantee"] = value
                    elif "ì‚¬ê³ " in label: res["accident"] = value
                    elif "ì‹¤ë‚´ì„¸ì°¨" in label: res["inner_car_wash"] = value
                    elif "ë³´í—˜" in label: res["insurance"] = value

        # --- [ì„¹ì…˜ 2] ìƒ‰ìƒ ---
        if len(sections) >= 2:
            color_items = sections[1].query_selector_all(".css-113wzqa")
            if len(color_items) >= 1: res["color_ext"] = color_items[0].query_selector(".css-1b7o1k1 + div").inner_text().strip()
            if len(color_items) >= 2: res["color_int"] = color_items[1].query_selector(".css-1b7o1k1 + div").inner_text().strip()

        # --- [ì„¹ì…˜ 3] ì˜µì…˜ ë° ì¶œê³  ì •ë³´ ---
        if len(sections) >= 3:
            sec3 = sections[2]
            # ì£¼ìš” ì˜µì…˜ (ì‰¼í‘œ ìœ ì§€)
            option_elements = sec3.query_selector_all(".css-5pr39e .css-1i3qy3r .css-vsdo2k .css-g5wwb2 .css-13wylk3")
            res["main_option"] = ", ".join([opt.inner_text().strip() for opt in option_elements if opt.inner_text().strip()])

            # 1) delivery_information (íŒŒì´í”„ ì ìš© ëŒ€ìƒ)
            ship_el = sec3.query_selector(".css-1cfq7ri .css-1n3oo4w")
            res["delivery_information"] = clean_text_to_pipe(ship_el.inner_text()) if ship_el else ""

        # --- [ì„¹ì…˜ 4] ê´€ë¦¬ìƒíƒœ (ì›ë³¸ ë°ì´í„° ìœ ì§€) ---
        if len(sections) >= 4:
            sec4 = sections[3]
            mgmt_items = sec4.query_selector_all(".css-113wzqa")
            keys_mgmt = ["tire", "tinting", "car_key"]
            for i, item in enumerate(mgmt_items):
                if i < len(keys_mgmt):
                    val = item.query_selector(".css-1b7o1k1 + div")
                    res[keys_mgmt[i]] = val.inner_text().strip() if val else ""

        # ì´ë¯¸ì§€ ìˆ˜ì§‘
        target_images = []
        if len(sections) >= 2: target_images.extend(sections[1].query_selector_all("img"))
        if len(sections) >= 4: target_images.extend(sections[3].query_selector_all("img"))
        target_images.extend(page.query_selector_all(".css-w9nhgi img, .css-q47uzu img, .css-1a3591h img"))

        downloaded_urls = set()
        img_idx = 1
        for img in target_images:
            src = img.get_attribute("src")
            if src and "svg" not in src and src not in downloaded_urls:
                download_image(src, model_cd, img_idx)
                downloaded_urls.add(src)
                img_idx += 1

        # 2) rec_reason (íŒŒì´í”„ ì ìš© ëŒ€ìƒ)
        rec_el = page.query_selector(".css-isc2b5 .css-yfldxx")
        res["rec_reason"] = clean_text_to_pipe(rec_el.inner_text()) if rec_el else ""

    except Exception as e:
        print(f"   âš ï¸ íŒŒì‹± ì—ëŸ¬: {e}")
    return res

def main():
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=False)
        context = browser.new_context(
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        )
        page = context.new_page()
        
        print("ğŸš€ í—¤ì´ë”œëŸ¬ ëª©ë¡ ìˆ˜ì§‘ ì‹œì‘...")
        page.goto(f"{BASE_URL}/market/cars", wait_until="domcontentloaded")
        raw_list, seen = [], set()
        
        while len(raw_list) < TEST_LIMIT:
            page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
            page.wait_for_timeout(2000)
            cards = page.query_selector_all('a[href^="/market/cars/"]')
            for card in cards:
                href = card.get_attribute("href").split("?")[0]
                if href not in seen:
                    seen.add(href)
                    raw_list.append(_extract_card_heydealer(card, len(raw_list) + 1))
                    if len(raw_list) >= TEST_LIMIT: break

        # ëª©ë¡ ì €ì¥
        list_fields = ["model_sn", "model_cd", "model_name", "model_second_name", "grade_name", "year", "km", "before_sale", "sale_price", "new_car_price", "accident", "insurance", "detail_url", "date_crtr_pnttm", "create_dt"]
        with open(RESULT_DIR / "heydealer_list.csv", "w", newline="", encoding="utf-8-sig") as f:
            writer = csv.DictWriter(f, fieldnames=list_fields, extrasaction='ignore')
            writer.writeheader()
            writer.writerows(raw_list)
        print(f"âœ… ëª©ë¡ ìˆ˜ì§‘ ì™„ë£Œ â†’ ê²½ë¡œ: {RESULT_DIR / 'heydealer_list.csv'} | íŒŒì¼ëª…: heydealer_list.csv")

        # ìƒì„¸ ìˆ˜ì§‘
        detail_results = []
        detail_fields = ["model_sn", "model_cd", "model_name", "model_second_name", "grade_name", "year", "km", "refund", "guarantee", "accident", "inner_car_wash", "insurance", "color_ext", "color_int", "main_option", "delivery_information", "rec_reason", "tire", "tinting", "car_key", "detail_url", "date_crtr_pnttm", "create_dt"]

        max_retries = 5
        for item in raw_list:
            success = False
            for retry in range(max_retries):
                if retry == 0:
                    print(f"ğŸ” ìƒì„¸ ìˆ˜ì§‘ ì¤‘: {item['model_cd']}")
                else:
                    remaining = max_retries - retry - 1
                    print(f"ğŸš¨ ìƒì„¸ ì¬ìˆ˜ì§‘ ì¤‘: {item['model_cd']} (ë‚¨ì€ íšŸìˆ˜ {remaining})")
                try:
                    page.goto(item["detail_url"], wait_until="domcontentloaded", timeout=40000)
                    time.sleep(3)
                    detail = _extract_detail_smart(page, item["model_sn"], item["model_cd"])
                    if detail.get("model_name"):
                        # ë‚ ì§œ ì •ë³´ ë™ê¸°í™”
                        detail.update({
                            "detail_url": item["detail_url"], 
                            "date_crtr_pnttm": item["date_crtr_pnttm"], 
                            "create_dt": item["create_dt"]
                        })
                        detail_results.append(detail)
                        success = True
                        if retry > 0:
                            print(f"   âœ… ì¬ìˆ˜ì§‘ ì„±ê³µ: {item['model_cd']}")
                        break
                except:
                    time.sleep(2)
            
            if not success:
                print(f"   âŒ ìƒì„¸ ìˆ˜ì§‘ ì‹¤íŒ¨: {item['model_cd']} (ì¬ì‹œë„ í›„ì—ë„ ë¯¸ìˆ˜ì§‘)")
                detail_results.append({
                    "model_sn": item["model_sn"], "model_cd": item["model_cd"], 
                    "detail_url": item["detail_url"], "date_crtr_pnttm": item["date_crtr_pnttm"], "create_dt": item["create_dt"]
                })

        with open(RESULT_DIR / "heydealer_detail.csv", "w", newline="", encoding="utf-8-sig") as f:
            writer = csv.DictWriter(f, fieldnames=detail_fields, extrasaction='ignore')
            writer.writeheader()
            writer.writerows(detail_results)
        print(f"âœ… ìƒì„¸ ìˆ˜ì§‘ ì™„ë£Œ â†’ ê²½ë¡œ: {RESULT_DIR / 'heydealer_cars_detail.csv'} | íŒŒì¼ëª…: heydealer_cars_detail.csv")
        
        print("âœ… ëª¨ë“  ìˆ˜ì§‘ ì™„ë£Œ")
        browser.close()

if __name__ == "__main__":
    main()